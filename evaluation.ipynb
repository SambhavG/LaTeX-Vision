{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{array}{r l r l r}{{\\overline{{}}}{\\overline{{{\\hat{c}}\\rangle}}}}&{{}}&{{\\underline{{{\\hat{c}}}}\\big\\}}}&{{\\underline{{{\\hat{c}}}}\\big\\}}}&{{\\underline{{{\\hat{c}}}}\\big\\}}}\\\\ {{\\overline{{{\\hat{c}}}}\\big\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pix2tex.cli import LatexOCR\n",
    "\n",
    "img = Image.open('./output.png')\n",
    "model = LatexOCR()\n",
    "print(model(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for 5 :   5\n",
      "Prediction for {\\psi} :   {\\psi}}}\n",
      "Prediction for 69\\cdot {{\\phi}}_{-s} :   {69\\\\\\}\\\\\\}\\\\cd\\\\\n",
      "Prediction for \\frac{33}{{\\pi}} :   \\frac{{\\pi}}}}}}\n",
      "Prediction for R-S :   R\n",
      "Prediction for \\frac{20}{326831} :   \\frac{{{\n",
      "Prediction for {18}^{{\\pi}}{\\phi} :   {18}^^^}^}}^{{\\\\\\{\\}}}}}}{\\}}{\\{\\}}}}}}}}{\\}}\n",
      "Prediction for 36 :   36\n",
      "Prediction for {25}_{{\\pi}} :   {25_{{\\\n",
      "Prediction for {\\cot{Z}\\times R}^{X} :   \\cot{{{{{K}}}\n",
      "Prediction for \\tan{19} :   \\tan{{{\n",
      "Prediction for \\int_{-\\infty}^{\\infty}n :   \\int_{-inininftyinin}inin^inin{\\inin\n",
      "Prediction for {\\sin{a}}_{X} :   \\sin{{X}}}}}}}}}}}\n",
      "Prediction for {\\theta} :   {\\theta}}}\n",
      "Prediction for 61 :   {\n",
      "Prediction for {\\delta} :   {\\dddelta\n",
      "Prediction for {W\\cdot 18}^{36} :   {W}}}\\}}cd}}\n",
      "Prediction for \\tan{\\tan{{\\nu}}} :   \\tan{{\\nu}}}}}}}}}}}}}{{\\\\\\nu}}}}}}}}}}}}}\n",
      "Prediction for 25/73 :   {25}}}\n",
      "Prediction for \\sum_{i=0}^{n}59 :   \\sum_{i}}}=}}n}}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "def balance_brackets(latex_code):\n",
    "    bracket_stack = []\n",
    "    bracket_pairs = {'{': '}', '[': ']', '(': ')'}\n",
    "    new_code = []\n",
    "    for char in latex_code:\n",
    "        if char in bracket_pairs:\n",
    "            bracket_stack.append(char)\n",
    "            new_code.append(char)\n",
    "        elif char in bracket_pairs.values():\n",
    "            if bracket_stack and bracket_pairs[bracket_stack[-1]] == char:\n",
    "                bracket_stack.pop()\n",
    "                new_code.append(char)\n",
    "            else:\n",
    "                for opening_bracket, closing_bracket in bracket_pairs.items():\n",
    "                    if closing_bracket == char:\n",
    "                        new_code.append(opening_bracket)\n",
    "                        bracket_stack.append(opening_bracket)\n",
    "                        new_code.append(char)\n",
    "                        break\n",
    "        else:\n",
    "            new_code.append(char)\n",
    "    while bracket_stack:\n",
    "        opening_bracket = bracket_stack.pop()\n",
    "        new_code.append(bracket_pairs[opening_bracket])\n",
    "    return ''.join(new_code)\n",
    "\n",
    "data_dir = './dataset1'\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-stage1\")\n",
    "finetuned_model = VisionEncoderDecoderModel.from_pretrained(\"./my_trained_model\")\n",
    "indices = random.sample(range(1000), 20)\n",
    "images = [(i, Image.open(data_dir + f'/{i}.png').convert(\"RGB\")) for i in indices]\n",
    "for i, image in images:\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = finetuned_model.generate(pixel_values, temperature=0.1, do_sample=True)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    # generated_text = balance_brackets(generated_text)\n",
    "    with open(data_dir + '/latex.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        line = lines[i].strip()\n",
    "\n",
    "    print('Prediction for', line, ':  ', generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for \\beta(e)=-\\frac{e^{3}}{16\\pi^{2}}(c_{gauge}+c_{\\lambda}+c_{q}+c_{sq}) :   {n}{}{}_{m\\\\\\{\\\\\\{{\\\\}}}}}\n",
      "Prediction for \\sum_{\\gamma\\in\\Gamma}\\frac{|\\gamma^{\\prime}(f({\\bfy}))|^{\\Delta}}{|f({\\bfx})-\\gammaf({\\bfy})|^{2\\Delta}}\\;=\\;|f^{\\prime}({\\bfx})|^{-\\Delta}|f^{\\prime}({\\bfy})|^{-\\Delta}\\sum_{\\gamma\\inf^{-1}\\Gammaf}\\frac{|\\gamma^{\\prime}({\\bfy})|^{\\Delta}}{|{\\bfx}-\\gamma{\\bfy}|^{2\\Delta}}. :   {_{_{_{sum_{m}}}m}^{\\\\\\{\\\\\\}\\{\\{\\\\{\\}{\\\\}{\\{\\{\\}\\}}\\\\-\\\\}{\\\\_{\\\\}}}}}\n",
      "Prediction for \\sum_{n}\\left(\\lambda_{n}+\\lambda_{n}^{\\prime}\\right)=\\mp1\\, :   {74}{}{}_{}{}^}{}{\\_{W}}{}}\n",
      "Prediction for \\delta^{ab}\\,\\delta_{xy}\\,=\\,\\langle\\,\\frac{\\deltaS}{\\delta\\bar{c}_{x}^{a}}\\,\\bar{c}_{y}^{b}\\,\\rangle\\,=\\,\\widetildeZ_{3}\\,\\langle\\,i(\\partialD_{r}c)_{x}^{a}\\,\\bar{c}_{y}^{b}\\,\\rangle\\,-\\,\\frac{Z_{\\lambda}\\lambda}{Z_{3}}\\,\\langle\\,(s_{r}B_{x}^{a})\\,\\bar{c}_{y}^{b}\\,\\rangle\\;. :   {n_{n}\\\\\\}\\{}{}\\{\\\\\\{\\}\\_{\\}}}\n",
      "Prediction for \\bar{\\lambda}_{\\theta}=\\partial_{1}\\bar{\\theta}+\\frac\\xi2\\bar{\\theta},\\qquad\\lambda_{1}^{\\mu}=\\partial_{1}A_{0}^{\\mu}+\\frac2\\phiA_{1}^{\\mu}+i\\bar{\\psi}\\Gamma^{\\mu}\\theta. :   {{d_{d}}}{{\\\\\\{\\\\\\i{\\{\\{\\}{\\{\\{{\\{\\{\\\\{\\}}}}}}}}}}}}\n",
      "Prediction for {H}_{\\mu\\nu\\lambda}=\\nabla_{\\mu}{B}_{\\nu\\lambda}-\\frac{1}{2}{\\calA}_{\\mu}^{T}{\\calL}{\\calF}_{\\nu\\lambda}+cyclic~permutations :   {{k}}{}\\\\\\k\\\\{\\\\\\u\\\\-\\\\m\\\\mu\\\\}{}}\n",
      "Prediction for \\muk^{\\prime\\prime\\prime}+3\\mukk^{\\prime}-\\lambdak^{\\prime}=0. :   {\\mu}{}{}\\{}\\\\}\n",
      "Prediction for L_{int}(x)=i\\hat{q}_{x}\\gamma^{\\mu}\\hat{A}_{x\\mu}\\hat{q}_{x}, :   Liii\\ii{ii{\\ii{{i}}}{\\}}i{}{\\{\\}{\\i}i{\\}ii}k{}{}k{\\}ki}{}{\\}{}{}}{}{}h{}}{}{}}\n",
      "Prediction for a(f,u)=(2\\pi)^{-3/2}\\intd\\mu(k,u)\\,a(k,u)f^{*}(k,u) :   {\\w{\\\\\\\\{\\\\{\\{\\\\w}}}{\\}}\\u}{}{}{\\}{}}\n",
      "Prediction for mL\\sim(mz_{M})^{b/2}\\,. :   {n\\\\\\{\\\\\\}\\\\_{\\{{\\}}}}{}{}{}}{}{}{}\\\\W}{}{}{}}\n",
      "Prediction for j(\\tau)=\\frac{E_{4}(\\tau)^{3}}{\\Delta(\\tau)}=\\frac{E_{6}(\\tau)^{2}}{\\Delta(\\tau)}+j(i)\\,,\\quadj(i)=1728\\,. :   {\\frac{\\{\\{\\w{\\}}}-}}\n",
      "Prediction for ds^{2}=H^{\\frac{p-3}{4}}\\Big(-fdt^{2}+\\sum_{i=1}^{p}(dx^{i})^{2}\\Big)+H^{\\frac{p+1}{4}}\\left(f^{-1}dr^{2}+r^{2}d\\Omega_{4-p}^{2}\\right)\\,. :   {i\\\\\\_{\\\\{\\\\\\W\\\\m\\\\-\\\\i\\{\\{\\\\{\\-\\{\\i\\-{\\\\--\\-}\\\\}{\\\\i{\\{\\{\\-{\\{\\i{\\\\}\\{\\}\\-i}}}}}}}}}}}}\n",
      "Prediction for X_{\\mathrm{max}}=-\\frac{b\\Bigl[b^{2}(1-4u^{2})+2b(1-4u)-3b(1+2c)\\Bigr]}{6(2b-3c)}, :   {l_{\\\\\\{\\\\\\u\\\\m\\\\}\\\\{\\\\{{\\\\}}\\\\w\\\\W\\\\-\\{\\{\\\\}{\\\\{\\{\\{\\}\\}{\\}}}}}}}\n",
      "Prediction for a={\\frac{3}{4}}-i\\omega\\,\\quadb={\\frac{3}{4}}+i\\omega\\,\\quadc=2\\, :   {u_{u}}{}_{u}{}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m balance_brackets(generated_text)\n\u001b[1;32m     11\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m balance_brackets(generated_text)\n\u001b[0;32m---> 12\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction for\u001b[39m\u001b[38;5;124m'\u001b[39m, code, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:  \u001b[39m\u001b[38;5;124m'\u001b[39m, generated_text)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./archive/im2latex_test.csv')\n",
    "indices = random.sample(range(1, 8000), 20)\n",
    "images = [(df.iloc[i, 0], Image.open('./archive/images/images/' + str(df.iloc[i, 1]))) for i in indices]\n",
    "for code, image in images:\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = finetuned_model.generate(pixel_values, temperature=0.1, do_sample=True)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    generated_text = balance_brackets(generated_text)\n",
    "    code = code.replace(\" \", \"\")\n",
    "    print('Prediction for', code, ':  ', generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.55224276549043 0.2877612138274522\n",
      "102.90763638470793 0.5145381819235396\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import random\n",
    "from cer import calculate_cer\n",
    "\n",
    "data_dir = './dataset1'\n",
    "finetuned_model = VisionEncoderDecoderModel.from_pretrained(\"./my_trained_model\")\n",
    "indices = random.sample(range(1000), 200)\n",
    "images = [(i, Image.open(data_dir + f'/{i}.png').convert(\"RGB\")) for i in indices]\n",
    "bleu = 0\n",
    "cer = 0\n",
    "for i, image in images:\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = finetuned_model.generate(pixel_values, temperature=0.1, do_sample=True)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    with open(data_dir + '/latex.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        line = lines[i].strip()\n",
    "    bleu += nltk.translate.bleu_score.sentence_bleu([[*line]], [*generated_text])\n",
    "    cer += calculate_cer([*line], [*generated_text])\n",
    "print(bleu, bleu / len(images))\n",
    "print(cer, cer / len(images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
